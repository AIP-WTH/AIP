{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "### original file\n",
    "\n",
    "https://github.com/openai/gpt-2-output-dataset/blob/master/baseline.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running this notebook\n",
    "\n",
    "1. Create /output folder\n",
    "   1. Insert all crawled dataset(csv)\n",
    "   1. Rename them as same with GPT dataset files.\n",
    "1. Create /log folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "# example code from https://github.com/SKT-AI/KoGPT2\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"skt/kogpt2-base-v2\",\n",
    "    bos_token=\"</s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    mask_token=\"<mask>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data + preprocessing\n",
    "\n",
    "def load_data(data_dir, crawled_dir, source):\n",
    "    path = os.path.join(data_dir, \"{}.csv\".format(source))\n",
    "    crawled_path = os.path.join(crawled_dir, \"{}.csv\".format(source))\n",
    "    dataset = list(csv.reader(open(path, encoding=\"utf8\")))\n",
    "    crawled_dataset = list(csv.reader(open(crawled_path, encoding=\"cp949\")))\n",
    "    n = len(dataset)\n",
    "\n",
    "    texts = []\n",
    "    labels = [1, 0] * n\n",
    "\n",
    "    for data in dataset:\n",
    "        idx = int(data[0])\n",
    "        tokens = tokenizer.tokenize(data[5])\n",
    "        texts.append(' '.join(tokens))\n",
    "        tokens = tokenizer.tokenize(crawled_dataset[idx][4])\n",
    "        texts.append(' '.join(tokens))\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "\n",
    "def main(\n",
    "    data_dir=\"data/\",\n",
    "    crawl_dir=\"output/\",\n",
    "    log_dir=\"log/\",\n",
    "    topics=[\"culture\", \"economy\", \"it_science\", \"politics\", \"society\", \"world\"],\n",
    "    train_test_ratio=0.1,\n",
    "):\n",
    "    texts_list, labels_list = [], []\n",
    "    for topic in topics:\n",
    "        texts, labels = load_data(data_dir, crawl_dir, topic)\n",
    "        texts_list.extend(texts)\n",
    "        labels_list.extend(labels)\n",
    "\n",
    "    texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
    "        texts_list, labels_list, test_size=train_test_ratio, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    vect = TfidfVectorizer()\n",
    "    train_features = vect.fit_transform(texts_train)\n",
    "    test_features = vect.transform(texts_test)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_features, labels_train)\n",
    "    test_accuracy = model.score(test_features, labels_test) * 100.0\n",
    "    result_proba = model.predict_proba(test_features)\n",
    "    result_log_proba = model.predict_log_proba(test_features)\n",
    "    ce_loss = 0\n",
    "    for label, value in zip(labels_test, result_log_proba):\n",
    "        ce_loss -= label * value[1] + (1 - label) * value[0]\n",
    "    ce_loss /= len(labels_test)\n",
    "    data = {\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"mse_loss\": np.sum(np.array(labels_test) - model.predict_proba(test_features)[:, 1]) ** 2 / len(labels_test),\n",
    "        \"ce_loss\": ce_loss,\n",
    "        \"label_and_result\": list(zip(labels_test, model.predict(test_features).tolist(), result_proba.tolist())),\n",
    "    }\n",
    "    print(data)\n",
    "    json.dump(data, open(os.path.join(log_dir, \"result.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_accuracy': 89.0, 'mse_loss': 0.06409735769225443, 'ce_loss': 0.4115393467022112, 'label_and_result': [(1, 1, [0.10611377796899635, 0.8938862220310037]), (0, 0, [0.7001699268963859, 0.29983007310361404]), (0, 0, [0.9373373834419062, 0.06266261655809384]), (0, 1, [0.48952946641272266, 0.5104705335872773]), (0, 0, [0.6970723336025466, 0.3029276663974534]), (0, 0, [0.8652607930036528, 0.1347392069963472]), (1, 1, [0.12125276108672156, 0.8787472389132784]), (0, 0, [0.7525794275363951, 0.24742057246360494]), (0, 0, [0.6680837107942625, 0.3319162892057374]), (0, 0, [0.8638836627478211, 0.1361163372521789]), (1, 1, [0.2769855907662836, 0.7230144092337164]), (1, 1, [0.1680113579910617, 0.8319886420089383]), (1, 1, [0.14080138402764975, 0.8591986159723503]), (1, 1, [0.27633333394205795, 0.723666666057942]), (1, 1, [0.4082642457485335, 0.5917357542514665]), (0, 0, [0.8449242298382185, 0.15507577016178148]), (1, 1, [0.27856944688494467, 0.7214305531150553]), (1, 1, [0.3228210987730924, 0.6771789012269076]), (1, 0, [0.5204852213473882, 0.47951477865261183]), (1, 1, [0.3288745963003701, 0.6711254036996299]), (1, 1, [0.2613632087424711, 0.7386367912575289]), (1, 1, [0.38933233993941463, 0.6106676600605854]), (0, 0, [0.5064623046177853, 0.4935376953822147]), (0, 1, [0.391237109147373, 0.608762890852627]), (1, 0, [0.5009800682472311, 0.49901993175276893]), (0, 0, [0.7082369534044366, 0.2917630465955634]), (0, 0, [0.6669333116201549, 0.3330666883798451]), (1, 1, [0.26542805434270056, 0.7345719456572994]), (1, 1, [0.42838358840387536, 0.5716164115961246]), (0, 1, [0.42177819944237127, 0.5782218005576287]), (1, 1, [0.20191883450375137, 0.7980811654962486]), (1, 1, [0.2438134818126967, 0.7561865181873033]), (1, 1, [0.3101599883690357, 0.6898400116309643]), (0, 0, [0.5980053422541601, 0.40199465774583987]), (1, 1, [0.2683842871117622, 0.7316157128882378]), (1, 1, [0.3713221722197082, 0.6286778277802918]), (0, 0, [0.8432284911961961, 0.15677150880380386]), (1, 0, [0.5508001254258892, 0.44919987457411087]), (1, 0, [0.9138132139238933, 0.08618678607610676]), (1, 1, [0.2152224739892189, 0.7847775260107811]), (1, 1, [0.453113436455451, 0.546886563544549]), (0, 0, [0.8648773897135036, 0.13512261028649644]), (0, 1, [0.35337520680157386, 0.6466247931984261]), (0, 0, [0.6050827428368865, 0.39491725716311354]), (1, 1, [0.22886210906105875, 0.7711378909389413]), (1, 1, [0.24706141099768753, 0.7529385890023125]), (0, 0, [0.548756707808661, 0.451243292191339]), (0, 0, [0.6654999588269459, 0.3345000411730541]), (1, 1, [0.2892171665601174, 0.7107828334398826]), (1, 1, [0.12427423787042802, 0.875725762129572]), (1, 1, [0.3776073720733586, 0.6223926279266414]), (0, 1, [0.4968569405286414, 0.5031430594713586]), (1, 1, [0.2715593571010997, 0.7284406428989003]), (1, 1, [0.3783456695554245, 0.6216543304445755]), (0, 0, [0.915169611424866, 0.08483038857513397]), (0, 0, [0.6542779099789494, 0.3457220900210506]), (1, 1, [0.4161869093657692, 0.5838130906342308]), (1, 1, [0.14978466485681652, 0.8502153351431835]), (1, 1, [0.2689809558892954, 0.7310190441107046]), (0, 0, [0.6201899607748853, 0.37981003922511464]), (0, 0, [0.9460707699858069, 0.05392923001419315]), (1, 1, [0.3052284207709737, 0.6947715792290263]), (0, 0, [0.5603915138662855, 0.4396084861337145]), (0, 0, [0.7527493434420697, 0.2472506565579303]), (0, 0, [0.587942390258646, 0.412057609741354]), (0, 0, [0.8841871964748507, 0.11581280352514933]), (0, 0, [0.6103668635092142, 0.3896331364907858]), (1, 1, [0.32101053741671004, 0.67898946258329]), (0, 0, [0.6061442705615803, 0.39385572943841973]), (0, 0, [0.9284634145783979, 0.07153658542160214]), (0, 0, [0.5906491438851297, 0.4093508561148703]), (0, 0, [0.607920860873865, 0.392079139126135]), (0, 0, [0.5134101470170398, 0.48658985298296026]), (1, 1, [0.16148196237161572, 0.8385180376283843]), (0, 0, [0.5205487651399858, 0.4794512348600142]), (1, 1, [0.2682463797856113, 0.7317536202143887]), (0, 0, [0.6519434294158855, 0.34805657058411454]), (0, 0, [0.7175522773833533, 0.28244772261664675]), (1, 1, [0.20795610937044318, 0.7920438906295568]), (0, 0, [0.7370453330195534, 0.26295466698044656]), (0, 0, [0.8504219509359925, 0.1495780490640075]), (0, 0, [0.6384964090890568, 0.36150359091094314]), (0, 0, [0.6045687895643028, 0.3954312104356971]), (0, 0, [0.8708318320764545, 0.1291681679235454]), (0, 0, [0.7933644727041783, 0.2066355272958217]), (1, 1, [0.37727122327841445, 0.6227287767215856]), (1, 1, [0.29830473733421337, 0.7016952626657866]), (1, 1, [0.1846785825670706, 0.8153214174329294]), (0, 0, [0.7514990049384382, 0.2485009950615617]), (0, 0, [0.6951554054508917, 0.3048445945491083]), (1, 1, [0.41839600071149874, 0.5816039992885013]), (0, 0, [0.8505112383396045, 0.14948876166039546]), (1, 1, [0.13737158777317315, 0.8626284122268268]), (0, 0, [0.542094447409841, 0.457905552590159]), (1, 1, [0.18309645289253507, 0.8169035471074649]), (0, 0, [0.8720376877232534, 0.12796231227674654]), (0, 0, [0.5653514359685654, 0.4346485640314346]), (0, 0, [0.7201664131269025, 0.2798335868730975]), (1, 1, [0.21370576432826927, 0.7862942356717307]), (0, 0, [0.8888153997553236, 0.1111846002446763]), (1, 1, [0.2068203473760647, 0.7931796526239353]), (0, 0, [0.7323884789424986, 0.26761152105750136]), (0, 0, [0.554005662507749, 0.44599433749225104]), (1, 1, [0.4748232105992437, 0.5251767894007563]), (0, 0, [0.5473059524147272, 0.45269404758527276]), (0, 0, [0.593749993473838, 0.40625000652616206]), (1, 1, [0.24976831165804392, 0.7502316883419561]), (1, 0, [0.5082302696801142, 0.4917697303198858]), (0, 0, [0.6905465532336614, 0.3094534467663386]), (1, 1, [0.37257096167932524, 0.6274290383206748]), (0, 0, [0.6965270467309547, 0.30347295326904533]), (0, 0, [0.839774497427874, 0.160225502572126]), (0, 0, [0.8228823276731082, 0.17711767232689182]), (0, 0, [0.9067987326516047, 0.09320126734839532]), (0, 0, [0.8413775669970363, 0.1586224330029638]), (1, 0, [0.53383251502597, 0.46616748497403]), (0, 0, [0.6455587346962743, 0.3544412653037256]), (0, 1, [0.4478362726407381, 0.5521637273592619]), (1, 1, [0.3244206165661382, 0.6755793834338618]), (0, 0, [0.7899468702061905, 0.21005312979380955]), (0, 0, [0.6977528353472251, 0.3022471646527749]), (1, 1, [0.4464146595845562, 0.5535853404154438]), (0, 0, [0.5433794384799879, 0.456620561520012]), (1, 1, [0.18744593589034286, 0.8125540641096571]), (0, 0, [0.7852273702768011, 0.21477262972319894]), (1, 0, [0.581638220553462, 0.4183617794465379]), (1, 1, [0.2566963706159038, 0.7433036293840962]), (1, 1, [0.3361689335561956, 0.6638310664438044]), (0, 0, [0.6042595528690513, 0.39574044713094864]), (1, 1, [0.10684752009365073, 0.8931524799063493]), (0, 0, [0.692734412734862, 0.30726558726513803]), (0, 0, [0.812229157113945, 0.1877708428860549]), (1, 1, [0.39301062101158557, 0.6069893789884144]), (0, 1, [0.49876862602284866, 0.5012313739771513]), (1, 1, [0.20113678256435574, 0.7988632174356443]), (0, 0, [0.8082265700726884, 0.19177342992731158]), (1, 1, [0.3958721422523914, 0.6041278577476086]), (0, 0, [0.751974888355557, 0.24802511164444302]), (0, 1, [0.42367590652150156, 0.5763240934784984]), (1, 1, [0.49938709445576435, 0.5006129055442357]), (0, 0, [0.8484879343354301, 0.1515120656645699]), (1, 1, [0.33034218260219417, 0.6696578173978058]), (1, 1, [0.3975278129090978, 0.6024721870909022]), (1, 1, [0.10280482998888296, 0.897195170011117]), (1, 1, [0.13697127215555072, 0.8630287278444493]), (1, 1, [0.41849177576399255, 0.5815082242360075]), (1, 1, [0.25911983018387064, 0.7408801698161294]), (0, 0, [0.5541023643121599, 0.4458976356878402]), (0, 0, [0.5413438568123283, 0.4586561431876716]), (1, 1, [0.3907940231704148, 0.6092059768295852]), (0, 1, [0.34955566492609125, 0.6504443350739088]), (0, 0, [0.9306684228354892, 0.06933157716451081]), (0, 0, [0.7405024049277864, 0.2594975950722136]), (1, 1, [0.33614229778446236, 0.6638577022155376]), (0, 0, [0.5402691407634397, 0.4597308592365603]), (0, 0, [0.897249637300041, 0.10275036269995895]), (1, 1, [0.07050133948730797, 0.929498660512692]), (0, 1, [0.46689432724643787, 0.5331056727535621]), (0, 0, [0.5807232468022412, 0.4192767531977588]), (1, 1, [0.11981697381152778, 0.8801830261884722]), (1, 1, [0.07153713641655868, 0.9284628635834413]), (1, 1, [0.3089418330204077, 0.6910581669795923]), (0, 0, [0.8722217001945849, 0.12777829980541505]), (1, 1, [0.2337320124148239, 0.7662679875851761]), (0, 0, [0.5656773824222959, 0.4343226175777041]), (1, 0, [0.558101041307159, 0.441898958692841]), (1, 1, [0.35099962706742804, 0.649000372932572]), (1, 1, [0.26581028772343096, 0.734189712276569]), (0, 0, [0.8386139411621837, 0.16138605883781632]), (0, 1, [0.46749800246169504, 0.532501997538305]), (1, 0, [0.5359435159504904, 0.46405648404950955]), (0, 0, [0.6953457270659849, 0.30465427293401515]), (1, 1, [0.417070477547253, 0.582929522452747]), (1, 1, [0.17397953992565895, 0.826020460074341]), (0, 0, [0.5473912562649198, 0.4526087437350802]), (1, 1, [0.14415607028631316, 0.8558439297136868]), (1, 1, [0.4234177592903481, 0.5765822407096519]), (0, 0, [0.5239983922288413, 0.47600160777115874]), (1, 1, [0.1130528038991857, 0.8869471961008143]), (1, 1, [0.48978225022593547, 0.5102177497740645]), (1, 1, [0.16349489705004105, 0.836505102949959]), (0, 0, [0.5727894879449977, 0.4272105120550023]), (1, 1, [0.38314475121815705, 0.616855248781843]), (1, 1, [0.300761209000612, 0.699238790999388]), (0, 0, [0.634613466532755, 0.3653865334672451]), (1, 1, [0.1743790252524997, 0.8256209747475003]), (1, 1, [0.260592710714744, 0.739407289285256]), (0, 1, [0.4717054252557641, 0.5282945747442359]), (1, 1, [0.40669845680094796, 0.593301543199052]), (0, 0, [0.5633577928017206, 0.43664220719827934]), (1, 1, [0.446420110946838, 0.553579889053162]), (1, 1, [0.2800557425492002, 0.7199442574507998]), (1, 1, [0.302386542004088, 0.697613457995912]), (0, 0, [0.7363602684279948, 0.2636397315720052]), (0, 0, [0.710854448120217, 0.2891455518797829]), (1, 1, [0.49288050717125165, 0.5071194928287484]), (0, 0, [0.6402918308138272, 0.35970816918617277]), (0, 0, [0.5757151386188566, 0.4242848613811434]), (0, 0, [0.7195602672593433, 0.28043973274065676]), (0, 1, [0.48323192444862273, 0.5167680755513773])]}\n"
     ]
    }
   ],
   "source": [
    "# run main function\n",
    "\n",
    "main(topics=[\"culture\", \"economy\", \"it_science\", \"society\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
